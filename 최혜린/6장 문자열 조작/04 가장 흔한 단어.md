# 풀이

```python
# 46ms, 14MB
class Solution:
    def mostCommonWord(self, paragraph: str, banned: List[str]) -> str:
        
        paragraph = [word.lower() for word in re.compile("[^a-zA-Z]").split(paragraph) if word != '']
        paragraph_dict = collections.Counter(paragraph)
        
        key_list = paragraph_dict.most_common(len(paragraph_dict))
        
        for key, value in key_list:
            if key not in set(banned):
                return key
```

```python
# 63ms, 13.9MB
class Solution:
    def mostCommonWord(self, paragraph: str, banned: List[str]) -> str:
        
        paragraph = [word.lower() for word in re.compile("[^a-zA-Z]").split(paragraph) if word != '']
        paragraph_dict = collections.Counter(paragraph)
        
        key_list = paragraph_dict.most_common(len(banned) + 1)
        
        for key, value in key_list:
            if key not in set(banned):
                return key
```

- re 정규식을 사용하여 알파벳이 아닌 모든 것으로 split하고 ‘’ 빈 문자열을 filtering한 후 lower을 적용한 리스트를 생성해줬다
- 그리고 collections의 Counter로 등장횟수 계산
- 사실 처음에는 Counter 딕셔너리의 전체 내용을 대상으로 for문을 돌리면서 banned list에 들어잇는지 확인하려고 했는데 생각해보니 어차피 banned list가 아무리 길어도 전체 길이보다 하나가 작아야하기 때문에 key_list 또한 len(banned) + 1로 해주었다. (그런데 시간이 더 오래걸린건 왜지...ㅎㅎ...)
- for문을 돌면서 가장 많이 등장한 단어부터 banned안에 있는지 확인 후 없으면 return해줌. 이때 set으로 변경해서 시간 복잡도를 O(1)로 줄임

# 학습해야하는 부분

- re 정규식: 알파벳이 아닌 문자를 모두 공백으로 치환함

```python
[word for word in re.sub(r'[^\w]', ' ', paragraph)]
```

# 가능한 풀이

```python
class Solution:
    def mostCommonWord(self, paragraph: str, banned: List[str]) -> str:
        
        paragraph = [word for word in re.sub("[^\w]", " ", paragraph).lower().split() if word not in set(banned)]
        paragraph_dict = collections.Counter(paragraph)
        most_common_word = paragraph_dict.most_common()
        
        return most_common_word[0][0]
```

- 정규식 활용하는 다양한 방법을 알 수 있었음!
- 그리고 List comprehension에서 바로 banned list에 들어있는지 체크하는 좋은 아이디어도!